{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文件\n",
    "dtype = {'row_id': 'int64',\n",
    "         'timestamp': 'int64',\n",
    "         'user_id': 'int32',\n",
    "         'content_id': 'int16',\n",
    "         'content_type_id': 'int8',\n",
    "         'task_container_id': 'int16',\n",
    "         'user_answer': 'int8',\n",
    "         'answered_correctly': 'int8',\n",
    "         'prior_question_elapsed_time': 'float32',\n",
    "         'prior_question_had_explanation': 'boolean'}\n",
    "\n",
    "columns = ['timestamp','user_id','content_id','content_type_id','task_container_id','user_answer','answered_correctly','prior_question_elapsed_time']\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    '/home/yao/dataset/Riiid-AIEd-Challenge-2020/train.csv',\n",
    "    header=0,\n",
    "    usecols=columns,\n",
    "    dtype=dtype)\n",
    "\n",
    "diff_df = pd.read_csv('data_init/difficulty.csv')\n",
    "lectures_df = pd.read_csv('/home/yao/dataset/Riiid-AIEd-Challenge-2020/lectures.csv')\n",
    "\n",
    "#过滤与合并df\n",
    "train_df = train_df[\n",
    "    train_df['prior_question_elapsed_time'].notnull() &\n",
    "    (train_df['answered_correctly']!=-1) & \n",
    "    (train_df['prior_question_elapsed_time']!=0 )\n",
    "]\n",
    "\n",
    "train_df[\"prior_question_elapsed_time\"] = train_df[\"prior_question_elapsed_time\"] // 1000\n",
    "\n",
    "ques_df = pd.read_csv('/home/yao/dataset/Riiid-AIEd-Challenge-2020/questions.csv')\n",
    "\n",
    "train_df = train_df.merge(ques_df,how=\"left\",left_on='content_id',right_on='question_id')\n",
    "train_df = train_df.drop(columns=['question_id'])\n",
    "\n",
    "diff_df['difficulty'] *= 10\n",
    "diff_df['difficulty']  = diff_df['difficulty'].round().astype('int')\n",
    "\n",
    "train_df = train_df.merge(diff_df,left_on='content_id',right_on='content_id')\n",
    "\n",
    "train_df = train_df.merge(lectures_df,how='left',left_on='content_id',right_on='lecture_id')\n",
    "train_df = train_df.drop(columns=['lecture_id',\n",
    "                                  'part_y','type_of','tags','correct_answer'])\n",
    "\n",
    "train_df['tag'] += 1\n",
    "train_df['tag'] = train_df['tag'].fillna(0).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['content_type_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计用户做题数量,发现相差悬殊\n",
    "user_content_num_dist = train_df.groupby(\"user_id\")['timestamp'].agg('count')\n",
    "user_content_num_dist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据上面的统计,把序列长度设置为128\n",
    "PAD_TOKEN = 0\n",
    "SEED = 1\n",
    "SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在用户中随机取SEQ_LEN*5数量的题目的,按4:1构建训练集验证集\n",
    "groups = train_df.sample(frac=1,random_state=SEED).groupby(\"user_id\").head(SEQ_LEN*5)\n",
    "groups = groups.sort_values(['user_id','timestamp'])\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "for _, row in  groups.groupby(\"user_id\").agg({\n",
    "    \"content_id\":list,\n",
    "    \"content_type_id\":list, \n",
    "    'difficulty':list,\n",
    "    \"part_x\":list, \n",
    "    'content_type_id':list,\n",
    "    'tag':list,\n",
    "    \"prior_question_elapsed_time\":list,\n",
    "    \"answered_correctly\":list, \n",
    "}).iterrows():\n",
    "    \n",
    "    length = len(row[\"content_id\"])\n",
    "    row = row.to_dict()\n",
    "    if length % SEQ_LEN == 0 and length>SEQ_LEN:\n",
    "        for i in range(int(length/SEQ_LEN)-2):\n",
    "            row_ = {k:row[k][i*SEQ_LEN:(i+1)*SEQ_LEN] for k in row}\n",
    "            \n",
    "            train_data.append({\n",
    "            \"content_id\" : row_[\"content_id\"],\n",
    "            \"content_type_id\":row_[\"content_type_id\"],\n",
    "            \"difficulty_id\":row_[\"difficulty\"],\n",
    "            \"tag_id\":row_[\"tag\"],\n",
    "            \"prior_question_elapsed_time\" : row_[\"prior_question_elapsed_time\"],\n",
    "            \"part_id\": row_[\"part_x\"],\n",
    "            \"pad_flag\" : [False]*SEQ_LEN,\n",
    "            \"answered_correctly\" : row_[\"answered_correctly\"],\n",
    "            })\n",
    "\n",
    "        row_ = {k:row[k][(i+1)*SEQ_LEN:(i+2)*SEQ_LEN] for k in row}\n",
    "        \n",
    "        if len(row_[\"content_id\"]) ==0:\n",
    "            continue\n",
    "        val_data.append({\n",
    "                \"content_id\" : row_[\"content_id\"],\n",
    "                \"content_type_id\":row_[\"content_type_id\"],\n",
    "                \"difficulty_id\":row_[\"difficulty\"],\n",
    "                \"tag_id\":row_[\"tag\"],\n",
    "                \"prior_question_elapsed_time\" : row_[\"prior_question_elapsed_time\"],\n",
    "                \"part_id\": row_[\"part_x\"],\n",
    "                \"pad_flag\" : [False]*SEQ_LEN,\n",
    "                \"answered_correctly\" : row_[\"answered_correctly\"],\n",
    "            })\n",
    "        \n",
    "        \n",
    "    elif length<SEQ_LEN:\n",
    "        pads = [PAD_TOKEN]*(SEQ_LEN-length)\n",
    "        train_data.append({\n",
    "            \"content_id\" : row[\"content_id\"]+pads,\n",
    "            \"content_type_id\": row[\"content_type_id\"]+pads,\n",
    "            \"difficulty_id\":row[\"difficulty\"]+pads,\n",
    "            \"tag_id\": row[\"tag\"]+pads,\n",
    "            \"prior_question_elapsed_time\" : row[\"prior_question_elapsed_time\"]+pads,\n",
    "            \"part_id\": row[\"part_x\"]+pads,\n",
    "            \"pad_flag\" : [False]*length + [True]*(SEQ_LEN-length),\n",
    "            \"answered_correctly\" : row[\"answered_correctly\"]+pads,\n",
    "        })\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        for i in range(length//SEQ_LEN):\n",
    "            row_ = {k:row[k][i*SEQ_LEN:(i+1)*SEQ_LEN] for k in row}\n",
    "            train_data.append({\n",
    "                \"content_id\" : row_[\"content_id\"],\n",
    "                \"content_type_id\":row_[\"content_type_id\"],\n",
    "                \"difficulty_id\":row_[\"difficulty\"],\n",
    "                \"tag_id\":row_[\"tag\"],\n",
    "                \"prior_question_elapsed_time\" : row_[\"prior_question_elapsed_time\"],\n",
    "                \"part_id\": row_[\"part_x\"],\n",
    "                \"pad_flag\" : [False]*SEQ_LEN,\n",
    "                \"answered_correctly\" : row_[\"answered_correctly\"],\n",
    "            })\n",
    "            \n",
    "            \n",
    "        pads = [PAD_TOKEN]*(SEQ_LEN-length%SEQ_LEN)\n",
    "        row_ = {k:row[k][(i+1)*SEQ_LEN:(i+2)*SEQ_LEN] for k in row}\n",
    "        \n",
    "        if len(row_[\"content_id\"]) ==0:\n",
    "            continue\n",
    "        \n",
    "        val_data.append({\n",
    "                \"content_id\" : row_[\"content_id\"]+pads,\n",
    "                \"content_type_id\": row_[\"content_type_id\"]+pads,\n",
    "                \"difficulty_id\":row_[\"difficulty\"]+pads,\n",
    "                \"tag_id\": row_[\"tag\"]+pads,\n",
    "                \"prior_question_elapsed_time\" : row_[\"prior_question_elapsed_time\"]+pads,\n",
    "                \"part_id\": row_[\"part_x\"]+pads,\n",
    "                \"pad_flag\" : [False]*len(row_[\"content_id\"]) + [True]*(SEQ_LEN-length%SEQ_LEN),\n",
    "                \"answered_correctly\" : row_[\"answered_correctly\"]+pads,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_data)-1,0,-1):\n",
    "    if len(val_data[i]['content_id']) == 0:\n",
    "        print(val_data[i]['content_type_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiiidData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return idx, self.data[idx][\"content_id\"], \\\n",
    "            self.data[idx][\"content_type_id\"], \\\n",
    "            self.data[idx][\"difficulty_id\"], \\\n",
    "            self.data[idx][\"tag_id\"], \\\n",
    "            self.data[idx][\"part_id\"], \\\n",
    "            self.data[idx][\"prior_question_elapsed_time\"], \\\n",
    "            self.data[idx][\"pad_flag\"], \\\n",
    "            self.data[idx][\"answered_correctly\"]\n",
    "\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    _, content_id, task_id, difficulty_id, tag_id, \\\n",
    "        part_id, prior_question_elapsed_time, pad_flag, labels = zip(*batch)\n",
    "    \n",
    "    content_id = torch.Tensor(content_id).long()\n",
    "    task_id = torch.Tensor(task_id).long()\n",
    "    difficulty_id = torch.Tensor(difficulty_id).long()\n",
    "    tag_id = torch.Tensor(tag_id).long()\n",
    "    part_id = torch.Tensor(part_id).long()\n",
    "    prior_question_elapsed_time = torch.Tensor(prior_question_elapsed_time).long()\n",
    "    masks = torch.Tensor(pad_flag).bool()\n",
    "    labels = torch.Tensor(labels)\n",
    "\n",
    "    return content_id, task_id, difficulty_id, tag_id, part_id, \\\n",
    "        prior_question_elapsed_time, masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = RiiidData(train_data)\n",
    "val_set = RiiidData(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    if len(i['content_id']) != 32:\n",
    "        print(len(i['content_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformer_model import Riiid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-3\n",
    "DMODEL = 256\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=2)\n",
    "\n",
    "dataloaders = {\n",
    "    'train':train_loader,\n",
    "    'val':val_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Riiid(dmodel = DMODEL,max_len = SEQ_LEN)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model,dataloaders,criterion,optimizer,num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch,num_epochs -1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else :\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = []\n",
    "            running_acc = []\n",
    "            \n",
    "            for data in dataloaders[phase]:\n",
    "                content_id, task_id, difficulty_id, tag_id, part_id, \\\n",
    "                    elapsed_time, masks, labels = data\n",
    "                pos_id = torch.arange(0, content_id.shape[1]).unsqueeze(0).repeat(\n",
    "                    content_id.shape[0], 1)\n",
    "\n",
    "                pos_id = pos_id.to(device)\n",
    "                task_id = task_id.to(device)\n",
    "                difficulty_id = difficulty_id.to(device)\n",
    "                tag_id = tag_id.to(device)\n",
    "                part_id = part_id.to(device)\n",
    "                elapsed_time = elapsed_time.to(device)\n",
    "                masks = masks.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    outputs = model(pos_id,task_id, difficulty_id,\n",
    "                        tag_id,elapsed_time,part_id,masks)\n",
    "\n",
    "                    _,preds = torch.max(outputs,2)\n",
    "                    loss = criterion(outputs[:,:,1], labels)\n",
    "                    running_loss.append(loss.item())\n",
    "\n",
    "                    running_acc.append(torch.sum(preds == labels.data).item()/labels.numel())\n",
    "                    if phase =='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "\n",
    "            epoch_acc = np.mean(running_acc)\n",
    "            epoch_loss = np.mean(running_loss)\n",
    "            # writer.add_scalar('Loss/{}'.format(phase), epoch_loss, epoch+1)\n",
    "            \n",
    "            \n",
    "            print('{} Loss: {:.4f} ACC: {:.6f}  Lr:: {}  spend: {}s'.format(phase,epoch_loss,epoch_acc,\n",
    "                                                                           optimizer.param_groups[0]['lr'],int(time.time()-epoch_start)))\n",
    "            \n",
    "            if phase =='val':\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            # if phase == 'val':\n",
    "            #     scheduler.step(epoch_loss)\n",
    "                \n",
    "        print()\n",
    "        \n",
    "        if (epoch+1) %20 == 0:\n",
    "            path = './acc_{}.pth'.format(round(float(best_acc),6))\n",
    "            torch.save(best_model_wts,path)\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m  {:.0f}s'.format(time_elapsed // 60,time_elapsed % 60))\n",
    "          \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer(model,dataloaders,criterion,optimizer,NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
